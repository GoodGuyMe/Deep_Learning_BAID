{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccb8cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T16:37:31.262994Z",
     "iopub.status.busy": "2024-04-09T16:37:31.262634Z",
     "iopub.status.idle": "2024-04-09T16:37:41.120601Z",
     "shell.execute_reply": "2024-04-09T16:37:41.119648Z"
    },
    "papermill": {
     "duration": 9.866527,
     "end_time": "2024-04-09T16:37:41.123213",
     "exception": false,
     "start_time": "2024-04-09T16:37:31.256686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19, VGG19_Weights, resnet50, ResNet50_Weights, resnet18\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf842f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T16:37:41.133535Z",
     "iopub.status.busy": "2024-04-09T16:37:41.133061Z",
     "iopub.status.idle": "2024-04-09T16:37:41.148695Z",
     "shell.execute_reply": "2024-04-09T16:37:41.147905Z"
    },
    "papermill": {
     "duration": 0.023094,
     "end_time": "2024-04-09T16:37:41.150942",
     "exception": false,
     "start_time": "2024-04-09T16:37:41.127848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]  # RGB\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "class BBDataset(Dataset):\n",
    "    def __init__(self, file_dir='dataset', type='train', test=False):\n",
    "        self.if_test = test\n",
    "        self.train_transformer = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transformer = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.images = []\n",
    "        self.pic_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        if type == 'train':\n",
    "            DATA = pd.read_csv(os.path.join(file_dir, 'train_set.csv'))\n",
    "        elif type == 'validation':\n",
    "            DATA = pd.read_csv(os.path.join(file_dir, 'val_set.csv'))\n",
    "        elif type == 'test':\n",
    "            DATA = pd.read_csv(os.path.join(file_dir, 'test_set.csv'))\n",
    "\n",
    "        labels = DATA['score'].values.tolist()\n",
    "        pic_paths = DATA['image'].values.tolist()\n",
    "        for i in tqdm(range(len(pic_paths))):\n",
    "            pic_path = os.path.join('/kaggle/input/cs4240-78-1', pic_paths[i])\n",
    "            label = float(labels[i] / 10)\n",
    "            self.pic_paths.append(pic_path)\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pic_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pic_path = self.pic_paths[index]\n",
    "        img = cv.imread(pic_path)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        if self.if_test:\n",
    "            img = self.test_transformer(img)\n",
    "        else:\n",
    "            img = self.train_transformer(img)\n",
    "\n",
    "        return img, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec556d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T16:37:41.160613Z",
     "iopub.status.busy": "2024-04-09T16:37:41.160229Z",
     "iopub.status.idle": "2024-04-09T16:37:41.180380Z",
     "shell.execute_reply": "2024-04-09T16:37:41.179390Z"
    },
    "papermill": {
     "duration": 0.027769,
     "end_time": "2024-04-09T16:37:41.182724",
     "exception": false,
     "start_time": "2024-04-09T16:37:41.154955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_mean_std(features):\n",
    "    batch_size, c = features.size()[:2]\n",
    "    features_mean = features.reshape(batch_size, c, -1).mean(dim=2).reshape(batch_size, c, 1, 1)\n",
    "    features_std = features.reshape(batch_size, c, -1).std(dim=2).reshape(batch_size, c, 1, 1) + 1e-6\n",
    "    return features_mean, features_std\n",
    "\n",
    "\n",
    "def adain(content_features, style_features):\n",
    "    content_mean, content_std = calc_mean_std(content_features)\n",
    "    style_mean, style_std = calc_mean_std(style_features)\n",
    "    normalized_features = style_std * (content_features - content_mean) / content_std + style_mean\n",
    "    return normalized_features\n",
    "\n",
    "\n",
    "class NonLocalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        conv_nd = nn.Conv2d\n",
    "        max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        bn = nn.GroupNorm\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                        kernel_size=1, stride=1, padding=0),\n",
    "                bn(16, self.in_channels)\n",
    "            )\n",
    "            nn.init.constant_(self.W[1].weight, 0)\n",
    "            nn.init.constant_(self.W[1].bias, 0)\n",
    "        else:\n",
    "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.constant_(self.W.weight, 0)\n",
    "            nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
    "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9635658e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-09T16:37:41.192445Z",
     "iopub.status.busy": "2024-04-09T16:37:41.192108Z",
     "iopub.status.idle": "2024-04-09T16:37:41.513979Z",
     "shell.execute_reply": "2024-04-09T16:37:41.512904Z"
    },
    "papermill": {
     "duration": 0.329383,
     "end_time": "2024-04-09T16:37:41.516201",
     "exception": false,
     "start_time": "2024-04-09T16:37:41.186818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50737/50737 [00:00<00:00, 309977.09it/s]\n",
      "100%|██████████| 3200/3200 [00:00<00:00, 268285.22it/s]\n"
     ]
    }
   ],
   "source": [
    "class VGG(nn.Module):   # output relu4-1\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        model = vgg19()\n",
    "        model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/vgg19-dcbb9e9d.pth'),\n",
    "                                        strict=False)\n",
    "        self.model = nn.Sequential(*model.features[:21])\n",
    "        self._freeze_params()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def _freeze_params(self):\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "class SAB(nn.Module):\n",
    "    def __init__(self, identity=False):\n",
    "        super(SAB, self).__init__()\n",
    "        model = resnet50()\n",
    "        self.model = nn.Module()\n",
    "        self.model.conv1 = model.conv1\n",
    "        self.model.bn1 = model.bn1\n",
    "        self.model.relu = model.relu\n",
    "        self.model.maxpool = model.maxpool\n",
    "\n",
    "        self.model.layer1 = model.layer1\n",
    "        self.model.layer2 = model.layer2\n",
    "\n",
    "        self.identity = identity\n",
    "\n",
    "        self.vgg = VGG()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # aligned to the output of VGG\n",
    "        sty = self.vgg(x)\n",
    "        aes = self.model.conv1(x)\n",
    "        aes = self.model.bn1(aes)\n",
    "        aes = self.model.relu(aes)\n",
    "        aes = self.model.maxpool(aes)\n",
    "\n",
    "        aes = self.model.layer1(aes)\n",
    "        aes = self.model.layer2(aes)\n",
    "\n",
    "        output = adain(aes, sty)\n",
    "        if self.identity:\n",
    "            output += aes\n",
    "\n",
    "        return F.relu(output)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth'),\n",
    "                                        strict=False)\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth', map_location=torch.device('cpu')),\n",
    "                                        strict=False)\n",
    "\n",
    "\n",
    "class GAB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAB, self).__init__()\n",
    "        model = resnet50()\n",
    "        self.model = nn.Module()\n",
    "        self.model.conv1 = model.conv1\n",
    "        self.model.bn1 = model.bn1\n",
    "        self.model.relu = model.relu\n",
    "        self.model.maxpool = model.maxpool\n",
    "\n",
    "        self.model.layer1 = model.layer1\n",
    "        self.model.layer2 = model.layer2\n",
    "        self.model.layer3 = model.layer3\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth'),\n",
    "                                        strict=False)\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth', map_location=torch.device('cpu')),\n",
    "                                        strict=False)\n",
    "class SAAN(nn.Module):\n",
    "    def __init__(self, num_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.GenAes = GAB()\n",
    "        self.StyAes = SAB()\n",
    "\n",
    "        self.NLB = NonLocalBlock(in_channels=1536)\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
    "\n",
    "        self.bn = nn.GroupNorm(16,1536)\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(1536 * 4, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, num_classes),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self._initial_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        gen_aes = self.GenAes(x)\n",
    "        sty_aes = self.StyAes(x)\n",
    "\n",
    "        sty_aes = self.max_pool(sty_aes)\n",
    "\n",
    "        all_aes = torch.cat((sty_aes, gen_aes), 1)\n",
    "        all_aes = self.NLB(all_aes)\n",
    "\n",
    "        all_aes = self.avg_pool(all_aes)\n",
    "        all_aes = self.bn(all_aes)\n",
    "\n",
    "        fc_input = torch.flatten(all_aes, start_dim=1)\n",
    "\n",
    "        output = self.predictor(fc_input)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _initial_weights(self):\n",
    "        for m in self.bn.modules():\n",
    "            if isinstance(m, nn.GroupNorm):\n",
    "                nn.init.normal_(m.weight.data, mean=1.0, std=0.02)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "        for m in self.predictor.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=0.02)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class ResNetPretrain(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetPretrain, self).__init__()\n",
    "        model = resnet50()\n",
    "        self.model = model\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=num_classes, bias=True),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        self._initial_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        features = self.model.layer4(x)\n",
    "        features_flat = self.model.avgpool(features)\n",
    "        features_flat = torch.flatten(features_flat, 1)\n",
    "        output = self.model.fc(features_flat)\n",
    "\n",
    "        return features, output\n",
    "\n",
    "    def _initial_weights(self):\n",
    "        for m in self.model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if isinstance(m, nn.GroupNorm):\n",
    "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "n_epochs = 44\n",
    "batch_size = 16\n",
    "validation_frequency = 2\n",
    "save_frequency = 2\n",
    "learning_rate = 1e-5\n",
    "device = \"cuda\"\n",
    "checkpoint_dir = \"/kaggle/working/SAAN\"\n",
    "\n",
    "train_dataset = BBDataset(file_dir='/kaggle/input/baid-csvs', type='train', test=False)\n",
    "val_dataset = BBDataset(file_dir='/kaggle/input/baid-csvs', type='validation', test=True)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(learning_rate, optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n",
    "    if epoch < 40:\n",
    "        lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    else:\n",
    "        lr = learning_rate * (0.1 ** 4)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def save_checkpoint(checkpoint_dir, model, epoch):\n",
    "    checkpoint_dir = checkpoint_dir\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    save_path = os.path.join(checkpoint_dir, f\"epoch_{epoch}.pth\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "def validate(model, val_loader, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    loss = nn.HuberLoss()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for step, val_data in enumerate(val_loader):\n",
    "            image = val_data[0].to(device)\n",
    "            label = val_data[1].to(device).float()\n",
    "\n",
    "            predicted_label = model(image).squeeze()\n",
    "            val_loss += loss(predicted_label, label).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(\"Epoch: %3d Validation loss: %.8f\" % (epoch, val_loss))\n",
    "\n",
    "\n",
    "def train():\n",
    "    loss_hist = []\n",
    "    model = SAAN(num_classes=1)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'GenAes' in name:\n",
    "            param.requires_grad = False\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss = nn.HuberLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.5, 0.999), weight_decay=5e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for step, train_data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            image = train_data[0].to(device)\n",
    "            label = train_data[1].to(device).float()\n",
    "\n",
    "            predicted_label = model(image).squeeze()\n",
    "            train_loss = loss(predicted_label, label)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += train_loss.item()\n",
    "\n",
    "        print(\"Epoch: %3d Step: %5d / %5d Train loss: %.8f\" % (epoch, step, len(train_loader), train_loss.item()))\n",
    "        loss_hist.append(epoch_loss)\n",
    "        adjust_learning_rate(learning_rate, optimizer, epoch)\n",
    "\n",
    "        if (epoch + 1) % validation_frequency == 0:\n",
    "            validate(model, val_loader, epoch)\n",
    "            print(\"Validation\")\n",
    "\n",
    "        if (epoch + 1) % save_frequency == 0:\n",
    "            save_checkpoint(checkpoint_dir, model, epoch)\n",
    "            print(\"Saved\")\n",
    "        \n",
    "\n",
    "    print(\"Done training\")\n",
    "    return loss_hist\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment when you want to train\n",
    "# Might take up to a day to train on two GPU T4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b356eaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T16:37:41.527113Z",
     "iopub.status.busy": "2024-04-09T16:37:41.526817Z",
     "iopub.status.idle": "2024-04-10T03:20:35.323180Z",
     "shell.execute_reply": "2024-04-10T03:20:35.322018Z"
    },
    "papermill": {
     "duration": 38573.818291,
     "end_time": "2024-04-10T03:20:35.339487",
     "exception": false,
     "start_time": "2024-04-09T16:37:41.521196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Step:  3171 /  3172 Train loss: 0.00221599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:993: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 Step:  3171 /  3172 Train loss: 0.00420552\n",
      "Epoch:   1 Validation loss: 0.00799185\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   2 Step:  3171 /  3172 Train loss: 0.00525758\n",
      "Epoch:   3 Step:  3171 /  3172 Train loss: 0.00374830\n",
      "Epoch:   3 Validation loss: 0.00671189\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   4 Step:  3171 /  3172 Train loss: 0.00462402\n",
      "Epoch:   5 Step:  3171 /  3172 Train loss: 0.00444665\n",
      "Epoch:   5 Validation loss: 0.00720812\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   6 Step:  3171 /  3172 Train loss: 0.00307403\n",
      "Epoch:   7 Step:  3171 /  3172 Train loss: 0.00388863\n",
      "Epoch:   7 Validation loss: 0.00686541\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   8 Step:  3171 /  3172 Train loss: 0.00099007\n",
      "Epoch:   9 Step:  3171 /  3172 Train loss: 0.01106400\n",
      "Epoch:   9 Validation loss: 0.00728497\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  10 Step:  3171 /  3172 Train loss: 0.00879841\n",
      "Epoch:  11 Step:  3171 /  3172 Train loss: 0.00766072\n",
      "Epoch:  11 Validation loss: 0.00691350\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  12 Step:  3171 /  3172 Train loss: 0.10371203\n",
      "Epoch:  13 Step:  3171 /  3172 Train loss: 0.00003025\n",
      "Epoch:  13 Validation loss: 0.00703852\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  14 Step:  3171 /  3172 Train loss: 0.00039435\n",
      "Epoch:  15 Step:  3171 /  3172 Train loss: 0.08495797\n",
      "Epoch:  15 Validation loss: 0.00694925\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  16 Step:  3171 /  3172 Train loss: 0.00700170\n",
      "Epoch:  17 Step:  3171 /  3172 Train loss: 0.00169230\n",
      "Epoch:  17 Validation loss: 0.00703620\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  18 Step:  3171 /  3172 Train loss: 0.00600471\n",
      "Epoch:  19 Step:  3171 /  3172 Train loss: 0.00264114\n",
      "Epoch:  19 Validation loss: 0.00702003\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  20 Step:  3171 /  3172 Train loss: 0.00577767\n",
      "Epoch:  21 Step:  3171 /  3172 Train loss: 0.00276296\n",
      "Epoch:  21 Validation loss: 0.00698046\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  22 Step:  3171 /  3172 Train loss: 0.00467552\n",
      "Epoch:  23 Step:  3171 /  3172 Train loss: 0.00324347\n",
      "Epoch:  23 Validation loss: 0.00694779\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  24 Step:  3171 /  3172 Train loss: 0.00410969\n",
      "Epoch:  25 Step:  3171 /  3172 Train loss: 0.00001794\n",
      "Epoch:  25 Validation loss: 0.00697459\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  26 Step:  3171 /  3172 Train loss: 0.00683705\n",
      "Epoch:  27 Step:  3171 /  3172 Train loss: 0.00521754\n",
      "Epoch:  27 Validation loss: 0.00698287\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  28 Step:  3171 /  3172 Train loss: 0.01040151\n",
      "Epoch:  29 Step:  3171 /  3172 Train loss: 0.00316646\n",
      "Epoch:  29 Validation loss: 0.00696767\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  30 Step:  3171 /  3172 Train loss: 0.00377883\n",
      "Epoch:  31 Step:  3171 /  3172 Train loss: 0.00712198\n",
      "Epoch:  31 Validation loss: 0.00707344\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  32 Step:  3171 /  3172 Train loss: 0.00051629\n",
      "Epoch:  33 Step:  3171 /  3172 Train loss: 0.00982599\n",
      "Epoch:  33 Validation loss: 0.00705038\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  34 Step:  3171 /  3172 Train loss: 0.00074378\n",
      "Epoch:  35 Step:  3171 /  3172 Train loss: 0.00193233\n",
      "Epoch:  35 Validation loss: 0.00702061\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  36 Step:  3171 /  3172 Train loss: 0.00130207\n",
      "Epoch:  37 Step:  3171 /  3172 Train loss: 0.00015237\n",
      "Epoch:  37 Validation loss: 0.00700020\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  38 Step:  3171 /  3172 Train loss: 0.00532570\n",
      "Epoch:  39 Step:  3171 /  3172 Train loss: 0.00684756\n",
      "Epoch:  39 Validation loss: 0.00703683\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  40 Step:  3171 /  3172 Train loss: 0.00547461\n",
      "Epoch:  41 Step:  3171 /  3172 Train loss: 0.00001561\n",
      "Epoch:  41 Validation loss: 0.00700781\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  42 Step:  3171 /  3172 Train loss: 0.00000030\n",
      "Epoch:  43 Step:  3171 /  3172 Train loss: 0.12672932\n",
      "Epoch:  43 Validation loss: 0.00702918\n",
      "Validation\n",
      "Saved\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "loss_hist = train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c610a29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T03:20:35.366220Z",
     "iopub.status.busy": "2024-04-10T03:20:35.365904Z",
     "iopub.status.idle": "2024-04-10T03:20:35.710238Z",
     "shell.execute_reply": "2024-04-10T03:20:35.709393Z"
    },
    "papermill": {
     "duration": 0.361851,
     "end_time": "2024-04-10T03:20:35.712493",
     "exception": false,
     "start_time": "2024-04-10T03:20:35.350642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loss plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463799b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T03:20:35.737624Z",
     "iopub.status.busy": "2024-04-10T03:20:35.737311Z",
     "iopub.status.idle": "2024-04-10T03:22:57.170566Z",
     "shell.execute_reply": "2024-04-10T03:22:57.169277Z"
    },
    "papermill": {
     "duration": 141.448696,
     "end_time": "2024-04-10T03:22:57.173169",
     "exception": false,
     "start_time": "2024-04-10T03:20:35.724473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6400/6400 [00:00<00:00, 335192.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "6400it [02:09, 49.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.46820528171712694, pvalue=0.0)\n",
      "PearsonRResult(statistic=0.48198943472598027, pvalue=0.0)\n",
      "0.77375\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BBDataset(file_dir='/kaggle/input/baid-csvs', type='test', test=True)\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    device = \"cuda\"\n",
    "    checkpoint_path = \"/kaggle/working/SAAN/epoch_43.pth\"\n",
    "    df = pd.read_csv('/kaggle/input/baid-csvs/test_set.csv')\n",
    "    predictions = []\n",
    "\n",
    "    model = SAAN(num_classes=1)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True, num_workers=8)\n",
    "    print(\"test\")\n",
    "    with torch.no_grad():\n",
    "        for step, test_data in tqdm(enumerate(test_loader)):\n",
    "            image = test_data[0].to(device)\n",
    "\n",
    "            predicted_label = model(image)\n",
    "            prediction = predicted_label.squeeze().cpu().numpy()\n",
    "            predictions.append(prediction * 10)\n",
    "\n",
    "    scores = df['score'].values.tolist()\n",
    "\n",
    "    print(scipy.stats.spearmanr(scores, predictions))\n",
    "    print(scipy.stats.pearsonr(scores, predictions))\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(len(scores)):\n",
    "        cls1 = 1 if scores[i] > 5 else 0\n",
    "        cls2 = 1 if predictions[i] > 5 else 0\n",
    "        if cls1 == cls2:\n",
    "            acc += 1\n",
    "    print(acc/len(scores))\n",
    "    df.insert(loc=2, column='prediction', value=predictions)\n",
    "    \n",
    "    save_dir = '/kaggle/working'\n",
    "\n",
    "    save_path = os.path.join(save_dir, 'result.csv')\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(\"done\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3b69f",
   "metadata": {
    "papermill": {
     "duration": 0.096533,
     "end_time": "2024-04-10T03:22:57.368669",
     "exception": false,
     "start_time": "2024-04-10T03:22:57.272136",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4642477,
     "sourceId": 7908673,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4645951,
     "sourceId": 7908740,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 15809,
     "sourceId": 19078,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 16205,
     "sourceId": 19540,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 21755,
     "sourceId": 25842,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 21755,
     "sourceId": 26132,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38732.444748,
   "end_time": "2024-04-10T03:23:00.555475",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-09T16:37:28.110727",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
