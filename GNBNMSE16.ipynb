{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23c4169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T09:28:24.303923Z",
     "iopub.status.busy": "2024-04-07T09:28:24.303635Z",
     "iopub.status.idle": "2024-04-07T09:28:38.830763Z",
     "shell.execute_reply": "2024-04-07T09:28:38.829718Z"
    },
    "papermill": {
     "duration": 14.534848,
     "end_time": "2024-04-07T09:28:38.833180",
     "exception": false,
     "start_time": "2024-04-07T09:28:24.298332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19, VGG19_Weights, resnet50, ResNet50_Weights, resnet18\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c3c4b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T09:28:38.842762Z",
     "iopub.status.busy": "2024-04-07T09:28:38.842282Z",
     "iopub.status.idle": "2024-04-07T09:28:38.856806Z",
     "shell.execute_reply": "2024-04-07T09:28:38.855886Z"
    },
    "papermill": {
     "duration": 0.021479,
     "end_time": "2024-04-07T09:28:38.858865",
     "exception": false,
     "start_time": "2024-04-07T09:28:38.837386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]  # RGB\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "class BBDataset(Dataset):\n",
    "    def __init__(self, file_dir='dataset', type='train', test=False):\n",
    "        self.if_test = test\n",
    "        self.train_transformer = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transformer = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.images = []\n",
    "        self.pic_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        if type == 'train':\n",
    "            DATA = pd.read_csv(os.path.join(file_dir, 'train_set.csv'))\n",
    "        elif type == 'validation':\n",
    "            DATA = pd.read_csv(os.path.join(file_dir, 'val_set.csv'))\n",
    "        elif type == 'test':\n",
    "            DATA = pd.read_csv(os.path.join(file_dir, 'test_set.csv'))\n",
    "\n",
    "        labels = DATA['score'].values.tolist()\n",
    "        pic_paths = DATA['image'].values.tolist()\n",
    "        for i in tqdm(range(len(pic_paths))):\n",
    "            pic_path = os.path.join('/kaggle/input/cs4240-78-1', pic_paths[i])\n",
    "            label = float(labels[i] / 10)\n",
    "            self.pic_paths.append(pic_path)\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pic_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pic_path = self.pic_paths[index]\n",
    "        img = cv.imread(pic_path)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        if self.if_test:\n",
    "            img = self.test_transformer(img)\n",
    "        else:\n",
    "            img = self.train_transformer(img)\n",
    "\n",
    "        return img, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5ef610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T09:28:38.867501Z",
     "iopub.status.busy": "2024-04-07T09:28:38.867021Z",
     "iopub.status.idle": "2024-04-07T09:28:38.885748Z",
     "shell.execute_reply": "2024-04-07T09:28:38.884892Z"
    },
    "papermill": {
     "duration": 0.025254,
     "end_time": "2024-04-07T09:28:38.887752",
     "exception": false,
     "start_time": "2024-04-07T09:28:38.862498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_mean_std(features):\n",
    "    batch_size, c = features.size()[:2]\n",
    "    features_mean = features.reshape(batch_size, c, -1).mean(dim=2).reshape(batch_size, c, 1, 1)\n",
    "    features_std = features.reshape(batch_size, c, -1).std(dim=2).reshape(batch_size, c, 1, 1) + 1e-6\n",
    "    return features_mean, features_std\n",
    "\n",
    "\n",
    "def adain(content_features, style_features):\n",
    "    content_mean, content_std = calc_mean_std(content_features)\n",
    "    style_mean, style_std = calc_mean_std(style_features)\n",
    "    normalized_features = style_std * (content_features - content_mean) / content_std + style_mean\n",
    "    return normalized_features\n",
    "\n",
    "\n",
    "class NonLocalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        conv_nd = nn.Conv2d\n",
    "        max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        bn = nn.GroupNorm\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                        kernel_size=1, stride=1, padding=0),\n",
    "                bn(16, self.in_channels)\n",
    "            )\n",
    "            nn.init.constant_(self.W[1].weight, 0)\n",
    "            nn.init.constant_(self.W[1].bias, 0)\n",
    "        else:\n",
    "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.constant_(self.W.weight, 0)\n",
    "            nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
    "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4614a8e0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-07T09:28:38.896468Z",
     "iopub.status.busy": "2024-04-07T09:28:38.896223Z",
     "iopub.status.idle": "2024-04-07T09:28:39.217453Z",
     "shell.execute_reply": "2024-04-07T09:28:39.216545Z"
    },
    "papermill": {
     "duration": 0.328069,
     "end_time": "2024-04-07T09:28:39.219536",
     "exception": false,
     "start_time": "2024-04-07T09:28:38.891467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50737/50737 [00:00<00:00, 325897.34it/s]\n",
      "100%|██████████| 3200/3200 [00:00<00:00, 312177.81it/s]\n"
     ]
    }
   ],
   "source": [
    "class VGG(nn.Module):   # output relu4-1\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        model = vgg19()\n",
    "        model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/vgg19-dcbb9e9d.pth'),\n",
    "                                        strict=False)\n",
    "        self.model = nn.Sequential(*model.features[:21])\n",
    "        self._freeze_params()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def _freeze_params(self):\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "class SAB(nn.Module):\n",
    "    def __init__(self, identity=False):\n",
    "        super(SAB, self).__init__()\n",
    "        model = resnet50()\n",
    "        self.model = nn.Module()\n",
    "        self.model.conv1 = model.conv1\n",
    "        self.model.bn1 = model.bn1\n",
    "        self.model.relu = model.relu\n",
    "        self.model.maxpool = model.maxpool\n",
    "\n",
    "        self.model.layer1 = model.layer1\n",
    "        self.model.layer2 = model.layer2\n",
    "\n",
    "        self.identity = identity\n",
    "\n",
    "        self.vgg = VGG()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # aligned to the output of VGG\n",
    "        sty = self.vgg(x)\n",
    "        aes = self.model.conv1(x)\n",
    "        aes = self.model.bn1(aes)\n",
    "        aes = self.model.relu(aes)\n",
    "        aes = self.model.maxpool(aes)\n",
    "\n",
    "        aes = self.model.layer1(aes)\n",
    "        aes = self.model.layer2(aes)\n",
    "\n",
    "        output = adain(aes, sty)\n",
    "        if self.identity:\n",
    "            output += aes\n",
    "\n",
    "        return F.relu(output)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth'),\n",
    "                                        strict=False)\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth', map_location=torch.device('cpu')),\n",
    "                                        strict=False)\n",
    "\n",
    "\n",
    "class GAB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAB, self).__init__()\n",
    "        model = resnet50()\n",
    "        self.model = nn.Module()\n",
    "        self.model.conv1 = model.conv1\n",
    "        self.model.bn1 = model.bn1\n",
    "        self.model.relu = model.relu\n",
    "        self.model.maxpool = model.maxpool\n",
    "\n",
    "        self.model.layer1 = model.layer1\n",
    "        self.model.layer2 = model.layer2\n",
    "        self.model.layer3 = model.layer3\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth'),\n",
    "                                        strict=False)\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load('/kaggle/input/baid/pytorch/fully_pretrained/2/epoch_99.pth', map_location=torch.device('cpu')),\n",
    "                                        strict=False)\n",
    "class SAAN(nn.Module):\n",
    "    def __init__(self, num_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.GenAes = GAB()\n",
    "        self.StyAes = SAB()\n",
    "\n",
    "        self.NLB = NonLocalBlock(in_channels=1536)\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(num_features=1536)\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(1536 * 4, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, num_classes),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self._initial_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        gen_aes = self.GenAes(x)\n",
    "        sty_aes = self.StyAes(x)\n",
    "\n",
    "        sty_aes = self.max_pool(sty_aes)\n",
    "\n",
    "        all_aes = torch.cat((sty_aes, gen_aes), 1)\n",
    "        all_aes = self.NLB(all_aes)\n",
    "\n",
    "        all_aes = self.avg_pool(all_aes)\n",
    "        all_aes = self.bn(all_aes)\n",
    "\n",
    "        fc_input = torch.flatten(all_aes, start_dim=1)\n",
    "\n",
    "        output = self.predictor(fc_input)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _initial_weights(self):\n",
    "        for m in self.bn.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.normal_(m.weight.data, mean=1.0, std=0.02)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "        for m in self.predictor.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=0.02)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class ResNetPretrain(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetPretrain, self).__init__()\n",
    "        model = resnet50()\n",
    "        self.model = model\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=num_classes, bias=True),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        self._initial_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        features = self.model.layer4(x)\n",
    "        features_flat = self.model.avgpool(features)\n",
    "        features_flat = torch.flatten(features_flat, 1)\n",
    "        output = self.model.fc(features_flat)\n",
    "\n",
    "        return features, output\n",
    "\n",
    "    def _initial_weights(self):\n",
    "        for m in self.model.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "n_epochs = 44\n",
    "batch_size = 16\n",
    "validation_frequency = 2\n",
    "save_frequency = 2\n",
    "learning_rate = 1e-5\n",
    "device = \"cuda\"\n",
    "checkpoint_dir = \"/kaggle/working/SAAN\"\n",
    "\n",
    "train_dataset = BBDataset(file_dir='/kaggle/input/baid-csvs', type='train', test=False)\n",
    "val_dataset = BBDataset(file_dir='/kaggle/input/baid-csvs', type='validation', test=True)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(learning_rate, optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n",
    "    if epoch < 40:\n",
    "        lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    else:\n",
    "        lr = learning_rate * (0.1 ** 4)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def save_checkpoint(checkpoint_dir, model, epoch):\n",
    "    checkpoint_dir = checkpoint_dir\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    save_path = os.path.join(checkpoint_dir, f\"epoch_{epoch}.pth\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "def validate(model, val_loader, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for step, val_data in enumerate(val_loader):\n",
    "            image = val_data[0].to(device)\n",
    "            label = val_data[1].to(device).float()\n",
    "\n",
    "            predicted_label = model(image).squeeze()\n",
    "            val_loss += loss(predicted_label, label).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(\"Epoch: %3d Validation loss: %.8f\" % (epoch, val_loss))\n",
    "\n",
    "\n",
    "def train():\n",
    "    loss_hist = []\n",
    "    model = SAAN(num_classes=1)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'GenAes' in name:\n",
    "            param.requires_grad = False\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.5, 0.999), weight_decay=5e-4)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for step, train_data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            image = train_data[0].to(device)\n",
    "            label = train_data[1].to(device).float()\n",
    "\n",
    "            predicted_label = model(image).squeeze()\n",
    "            train_loss = loss(predicted_label, label)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += train_loss.item()\n",
    "\n",
    "        print(\"Epoch: %3d Step: %5d / %5d Train loss: %.8f\" % (epoch, step, len(train_loader), train_loss.item()))\n",
    "        loss_hist.append(epoch_loss)\n",
    "        adjust_learning_rate(learning_rate, optimizer, epoch)\n",
    "\n",
    "        if (epoch + 1) % validation_frequency == 0:\n",
    "            validate(model, val_loader, epoch)\n",
    "            print(\"Validation\")\n",
    "\n",
    "        if (epoch + 1) % save_frequency == 0:\n",
    "            save_checkpoint(checkpoint_dir, model, epoch)\n",
    "            print(\"Saved\")\n",
    "        \n",
    "\n",
    "    print(\"Done training\")\n",
    "    return loss_hist\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment when you want to train\n",
    "# Might take up to a day to train on two GPU T4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2eaf30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T09:28:39.229713Z",
     "iopub.status.busy": "2024-04-07T09:28:39.229108Z",
     "iopub.status.idle": "2024-04-07T20:35:51.148385Z",
     "shell.execute_reply": "2024-04-07T20:35:51.147064Z"
    },
    "papermill": {
     "duration": 40031.939651,
     "end_time": "2024-04-07T20:35:51.163669",
     "exception": false,
     "start_time": "2024-04-07T09:28:39.224018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Step:  3171 /  3172 Train loss: 0.06959876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 Step:  3171 /  3172 Train loss: 0.14036919\n",
      "Epoch:   1 Validation loss: 0.01834656\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   2 Step:  3171 /  3172 Train loss: 0.00609449\n",
      "Epoch:   3 Step:  3171 /  3172 Train loss: 0.31623152\n",
      "Epoch:   3 Validation loss: 0.01679533\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   4 Step:  3171 /  3172 Train loss: 0.00611404\n",
      "Epoch:   5 Step:  3171 /  3172 Train loss: 0.02992497\n",
      "Epoch:   5 Validation loss: 0.01591431\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   6 Step:  3171 /  3172 Train loss: 0.01527123\n",
      "Epoch:   7 Step:  3171 /  3172 Train loss: 0.00755117\n",
      "Epoch:   7 Validation loss: 0.01501672\n",
      "Validation\n",
      "Saved\n",
      "Epoch:   8 Step:  3171 /  3172 Train loss: 0.00599783\n",
      "Epoch:   9 Step:  3171 /  3172 Train loss: 0.00601366\n",
      "Epoch:   9 Validation loss: 0.01449913\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  10 Step:  3171 /  3172 Train loss: 0.00021033\n",
      "Epoch:  11 Step:  3171 /  3172 Train loss: 0.00632004\n",
      "Epoch:  11 Validation loss: 0.01368769\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  12 Step:  3171 /  3172 Train loss: 0.00645352\n",
      "Epoch:  13 Step:  3171 /  3172 Train loss: 0.01366843\n",
      "Epoch:  13 Validation loss: 0.01389709\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  14 Step:  3171 /  3172 Train loss: 0.00193698\n",
      "Epoch:  15 Step:  3171 /  3172 Train loss: 0.00880254\n",
      "Epoch:  15 Validation loss: 0.01392638\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  16 Step:  3171 /  3172 Train loss: 0.01449688\n",
      "Epoch:  17 Step:  3171 /  3172 Train loss: 0.00549869\n",
      "Epoch:  17 Validation loss: 0.01416161\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  18 Step:  3171 /  3172 Train loss: 0.17765135\n",
      "Epoch:  19 Step:  3171 /  3172 Train loss: 0.01492305\n",
      "Epoch:  19 Validation loss: 0.01378826\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  20 Step:  3171 /  3172 Train loss: 0.01109400\n",
      "Epoch:  21 Step:  3171 /  3172 Train loss: 0.00518204\n",
      "Epoch:  21 Validation loss: 0.01395937\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  22 Step:  3171 /  3172 Train loss: 0.00634758\n",
      "Epoch:  23 Step:  3171 /  3172 Train loss: 0.00188449\n",
      "Epoch:  23 Validation loss: 0.01400108\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  24 Step:  3171 /  3172 Train loss: 0.00688820\n",
      "Epoch:  25 Step:  3171 /  3172 Train loss: 0.22507033\n",
      "Epoch:  25 Validation loss: 0.01405994\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  26 Step:  3171 /  3172 Train loss: 0.00453756\n",
      "Epoch:  27 Step:  3171 /  3172 Train loss: 0.00767682\n",
      "Epoch:  27 Validation loss: 0.01388893\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  28 Step:  3171 /  3172 Train loss: 0.00747195\n",
      "Epoch:  29 Step:  3171 /  3172 Train loss: 0.00064261\n",
      "Epoch:  29 Validation loss: 0.01389736\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  30 Step:  3171 /  3172 Train loss: 0.01009211\n",
      "Epoch:  31 Step:  3171 /  3172 Train loss: 0.01117665\n",
      "Epoch:  31 Validation loss: 0.01371962\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  32 Step:  3171 /  3172 Train loss: 0.07892741\n",
      "Epoch:  33 Step:  3171 /  3172 Train loss: 0.01443062\n",
      "Epoch:  33 Validation loss: 0.01410135\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  34 Step:  3171 /  3172 Train loss: 0.01294724\n",
      "Epoch:  35 Step:  3171 /  3172 Train loss: 0.01652656\n",
      "Epoch:  35 Validation loss: 0.01366270\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  36 Step:  3171 /  3172 Train loss: 0.01223330\n",
      "Epoch:  37 Step:  3171 /  3172 Train loss: 0.00235116\n",
      "Epoch:  37 Validation loss: 0.01394289\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  38 Step:  3171 /  3172 Train loss: 0.00321600\n",
      "Epoch:  39 Step:  3171 /  3172 Train loss: 0.00970542\n",
      "Epoch:  39 Validation loss: 0.01400571\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  40 Step:  3171 /  3172 Train loss: 0.00973411\n",
      "Epoch:  41 Step:  3171 /  3172 Train loss: 0.00702382\n",
      "Epoch:  41 Validation loss: 0.01393233\n",
      "Validation\n",
      "Saved\n",
      "Epoch:  42 Step:  3171 /  3172 Train loss: 0.00132333\n",
      "Epoch:  43 Step:  3171 /  3172 Train loss: 0.01527496\n",
      "Epoch:  43 Validation loss: 0.01383522\n",
      "Validation\n",
      "Saved\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "loss_hist = train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59567ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T20:35:51.195486Z",
     "iopub.status.busy": "2024-04-07T20:35:51.195131Z",
     "iopub.status.idle": "2024-04-07T20:35:51.632130Z",
     "shell.execute_reply": "2024-04-07T20:35:51.631214Z"
    },
    "papermill": {
     "duration": 0.458851,
     "end_time": "2024-04-07T20:35:51.634333",
     "exception": false,
     "start_time": "2024-04-07T20:35:51.175482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loss plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748d1653",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T20:35:51.661895Z",
     "iopub.status.busy": "2024-04-07T20:35:51.661532Z",
     "iopub.status.idle": "2024-04-07T20:38:26.164699Z",
     "shell.execute_reply": "2024-04-07T20:38:26.163598Z"
    },
    "papermill": {
     "duration": 154.519399,
     "end_time": "2024-04-07T20:38:26.166760",
     "exception": false,
     "start_time": "2024-04-07T20:35:51.647361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6400/6400 [00:00<00:00, 293657.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "6400it [02:19, 45.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.4716524999536722, pvalue=0.0)\n",
      "PearsonRResult(statistic=0.46011055998894224, pvalue=0.0)\n",
      "0.77609375\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BBDataset(file_dir='/kaggle/input/baid-csvs', type='test', test=True)\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    device = \"cuda\"\n",
    "    checkpoint_path = \"/kaggle/working/SAAN/epoch_43.pth\"\n",
    "    df = pd.read_csv('/kaggle/input/baid-csvs/test_set.csv')\n",
    "    predictions = []\n",
    "\n",
    "    model = SAAN(num_classes=1)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True, num_workers=8)\n",
    "    print(\"test\")\n",
    "    with torch.no_grad():\n",
    "        for step, test_data in tqdm(enumerate(test_loader)):\n",
    "            image = test_data[0].to(device)\n",
    "\n",
    "            predicted_label = model(image)\n",
    "            prediction = predicted_label.squeeze().cpu().numpy()\n",
    "            predictions.append(prediction * 10)\n",
    "\n",
    "    scores = df['score'].values.tolist()\n",
    "\n",
    "    print(scipy.stats.spearmanr(scores, predictions))\n",
    "    print(scipy.stats.pearsonr(scores, predictions))\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(len(scores)):\n",
    "        cls1 = 1 if scores[i] > 5 else 0\n",
    "        cls2 = 1 if predictions[i] > 5 else 0\n",
    "        if cls1 == cls2:\n",
    "            acc += 1\n",
    "    print(acc/len(scores))\n",
    "    df.insert(loc=2, column='prediction', value=predictions)\n",
    "    \n",
    "    save_dir = '/kaggle/working'\n",
    "\n",
    "    save_path = os.path.join(save_dir, 'result.csv')\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(\"done\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a8e74",
   "metadata": {
    "papermill": {
     "duration": 0.105412,
     "end_time": "2024-04-07T20:38:26.390849",
     "exception": false,
     "start_time": "2024-04-07T20:38:26.285437",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4642477,
     "sourceId": 7908673,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4645951,
     "sourceId": 7908740,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 15809,
     "sourceId": 19078,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 16205,
     "sourceId": 19540,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 21755,
     "sourceId": 25842,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 21755,
     "sourceId": 26132,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40209.242349,
   "end_time": "2024-04-07T20:38:29.506141",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-07T09:28:20.263792",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
